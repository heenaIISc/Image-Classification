{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "29152de7",
      "metadata": {
        "id": "29152de7"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Traffic sign recognition is a challenging, real-world problem relevant for AI based transportation systems. Traffic signs show a wide range of variations between classes in terms of color, shape, and the presence of pictograms or text. However, there exist subsets of\n",
        "classes (e.g., speed limit signs) that are very similar to each other. Further, the classifier\n",
        "has to be robust against large variations in visual appearances due to changes in illumination, partial\n",
        "occlusions, rotations, weather conditions etc. Using a comprehensive traffic sign detection dataset, here we will perform classification of traffic signs, train and evaluate the different models and compare to the performance of MLPs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58facc94",
      "metadata": {
        "id": "58facc94"
      },
      "source": [
        "![img](https://paperswithcode.com/media/datasets/GTSRB-0000000633-9ce3c5f6_Dki5Rsf.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "surprising-uruguay",
      "metadata": {
        "id": "surprising-uruguay"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "The data for this mini-project is from the German Traffic Sign Detection Benchmark [GTSDB](https://benchmark.ini.rub.de/gtsdb_dataset.html). This archive contains the training set used during the IJCNN 2013 competition.\n",
        "\n",
        "The German Traffic Sign Detection Benchmark is a single-image detection assessment for researchers with interest in the field of computer vision, pattern recognition and image-based driver assistance. It is introduced on the IEEE International Joint Conference on Neural Networks 2013.\n",
        "\n",
        "It features ...\n",
        "\n",
        "* The main archive FullIJCNN2013.zip includes the images (1360 x 800 pixels) in PPM format, the image sections containing only the traffic signs\n",
        "* A file in CSV format with the ground truth\n",
        "* A ReadMe.txt with more details.\n",
        "\n",
        "Note that we will be using the images inside the image sections subfolders, containing only the traffic signs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ih-oasWmdZul",
      "metadata": {
        "id": "ih-oasWmdZul"
      },
      "source": [
        "## Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qfWGmjNHdZul",
      "metadata": {
        "id": "qfWGmjNHdZul"
      },
      "source": [
        "To build and improve upon a machine learning model for the classification of images and achieve a high accuracy final model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "812a816f",
      "metadata": {
        "cellView": "form",
        "id": "812a816f"
      },
      "outputs": [],
      "source": [
        "#@title Download the data\n",
        "!wget -qq https://sid.erda.dk/public/archives/ff17dc924eba88d5d01a807357d6614c/FullIJCNN2013.zip\n",
        "!unzip -qq FullIJCNN2013.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abstract-stocks",
      "metadata": {
        "id": "abstract-stocks"
      },
      "source": [
        "### Import Required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "advisory-knowing",
      "metadata": {
        "id": "advisory-knowing"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from skimage.io import imread, imshow\n",
        "from sklearn import preprocessing\n",
        "import os, glob\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc5c2362",
      "metadata": {
        "id": "fc5c2362"
      },
      "outputs": [],
      "source": [
        "images_data = glob.glob(\"/content/FullIJCNN2013/*/*.ppm\")\n",
        "len(images_data), images_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5b433fd",
      "metadata": {
        "id": "c5b433fd"
      },
      "outputs": [],
      "source": [
        "features, labels = [], []\n",
        "for i in images_data:\n",
        "    try:\n",
        "        img = Image.open(i)\n",
        "        img = img.resize((30,30))#.reshape(30*30*3)\n",
        "        labels.append(int(i.split(\"/\")[3]))\n",
        "        features.append(np.array(img))\n",
        "    except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HRbd6SBE_0vY",
      "metadata": {
        "id": "HRbd6SBE_0vY"
      },
      "outputs": [],
      "source": [
        "features[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccbb94db",
      "metadata": {
        "id": "ccbb94db"
      },
      "outputs": [],
      "source": [
        "features1 = np.array([i.reshape(-1) for i in features])\n",
        "features1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7W4QNo-w0prA",
      "metadata": {
        "id": "7W4QNo-w0prA"
      },
      "outputs": [],
      "source": [
        "n_classes = len(set(labels))\n",
        "n_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Vky31w5Ef5YV",
      "metadata": {
        "id": "Vky31w5Ef5YV"
      },
      "source": [
        "### Data Exploration and Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ca63666",
      "metadata": {
        "id": "9ca63666"
      },
      "source": [
        "#### Plot the sample image of each class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c414e14e",
      "metadata": {
        "id": "c414e14e"
      },
      "outputs": [],
      "source": [
        "plt.imshow(imread('/content/FullIJCNN2013/01/00002.ppm'))\n",
        "imread('/content/FullIJCNN2013/01/00002.ppm').shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08IEGHf80lhP",
      "metadata": {
        "id": "08IEGHf80lhP"
      },
      "outputs": [],
      "source": [
        "targets = np.array(labels)\n",
        "plt.figure(figsize=(16, 16))\n",
        "for c in range(n_classes):\n",
        "    i = np.random.choice(np.where(targets == c)[0])\n",
        "    plt.subplot(8, 8, c+1)\n",
        "    plt.axis('off')\n",
        "    plt.title('class: {}'.format(c))\n",
        "    plt.imshow(features[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a2rqCM-sIbY",
      "metadata": {
        "id": "8a2rqCM-sIbY"
      },
      "source": [
        "#### Plot the distribution of Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nwWKGQMFsIDP",
      "metadata": {
        "id": "nwWKGQMFsIDP"
      },
      "outputs": [],
      "source": [
        "# Visulization of the histogram\n",
        "images_per_class, bins, _ = plt.hist(labels,bins=range(n_classes))\n",
        "plt.xticks(range(n_classes))\n",
        "plt.title('histogram')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37b23a0b",
      "metadata": {
        "id": "37b23a0b"
      },
      "source": [
        "#### Normalize the features\n",
        "\n",
        "For most image data, the pixel values are integers with values between 0 and 255.\n",
        "\n",
        "Neural networks process inputs using small weight values, and inputs with large integer values can disrupt or slow down the learning process. As such it is good practice to normalize the pixel values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82239736",
      "metadata": {
        "id": "82239736"
      },
      "outputs": [],
      "source": [
        "features_norm = preprocessing.normalize(features1, norm='l2')\n",
        "features_norm.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28ea9c3a",
      "metadata": {
        "id": "28ea9c3a"
      },
      "source": [
        "### Train the MLP classifier on features\n",
        "\n",
        "* Split the data into train and test\n",
        "\n",
        "* Train the MLP classifier with different parameters\n",
        "\n",
        "* Get the accuracy score and performance metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f952950",
      "metadata": {
        "id": "7f952950"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(np.array(features_norm), np.array(labels), test_size=0.2)\n",
        "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfe1e294",
      "metadata": {
        "id": "dfe1e294"
      },
      "source": [
        "### Tune the hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa798fa3",
      "metadata": {
        "id": "fa798fa3"
      },
      "outputs": [],
      "source": [
        "mlp = MLPClassifier(max_iter=100)\n",
        "parameter_space = {\n",
        "    'hidden_layer_sizes': [(450,225,100,50), (100,100,50), (100,)],\n",
        "    'activation': ['tanh', 'relu'],\n",
        "    'solver': ['sgd', 'adam'],\n",
        "    'alpha': [0.0001, 0.05],\n",
        "    'learning_rate': ['constant','adaptive'],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eed63fc8",
      "metadata": {
        "id": "eed63fc8"
      },
      "outputs": [],
      "source": [
        "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n",
        "clf.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3ac351f",
      "metadata": {
        "id": "c3ac351f"
      },
      "outputs": [],
      "source": [
        "# Best parameter set\n",
        "print('Best parameters found:\\n', clf.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f29ce38e",
      "metadata": {
        "id": "f29ce38e"
      },
      "outputs": [],
      "source": [
        "mlp = MLPClassifier(activation='tanh',momentum=0.99,alpha=0.0001,max_iter=1000,\n",
        "                    hidden_layer_sizes=(450,225,100, 50),learning_rate='adaptive',solver='adam')\n",
        "mlp.fit(X_train, Y_train)\n",
        "mlp.score(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "y7nh3qVgFCJg",
      "metadata": {
        "id": "y7nh3qVgFCJg"
      },
      "source": [
        "#### Classification report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ImMJgHngFHSD",
      "metadata": {
        "id": "ImMJgHngFHSD"
      },
      "outputs": [],
      "source": [
        "pred_test = mlp.predict(X_test)\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(Y_test, pred_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dva2S313pIU",
      "metadata": {
        "id": "8dva2S313pIU"
      },
      "outputs": [],
      "source": [
        "metrics.confusion_matrix(Y_test, pred_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_aL1cw5L30tq",
      "metadata": {
        "id": "_aL1cw5L30tq"
      },
      "outputs": [],
      "source": [
        "def plot_gallery(images, titles, h, w, n_row=3, n_col=4):\n",
        "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
        "    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
        "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
        "    for i in range(n_row * n_col):\n",
        "        plt.subplot(n_row, n_col, i + 1)\n",
        "        plt.imshow(images[i].reshape((h, w,3)), cmap=plt.cm.gray)\n",
        "        plt.title(titles[i], size=12)\n",
        "        plt.xticks(())\n",
        "        plt.yticks(())\n",
        "\n",
        "def title(y_pred, y_test, target_names, i):\n",
        "    pred_name = target_names[y_pred[i]]\n",
        "    true_name = target_names[y_test[i]]\n",
        "    return 'predicted: %s\\ntrue:      %s' % (pred_name, true_name)\n",
        "\n",
        "prediction_titles = [title(pred_test, Y_test, Y_test, i)\n",
        "                     for i in range(pred_test.shape[0])]\n",
        "\n",
        "plot_gallery(X_test, prediction_titles, 30, 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hvKwKPdfpY6N",
      "metadata": {
        "id": "hvKwKPdfpY6N"
      },
      "source": [
        "#### Use RandomSearchCV to search the hyper parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JmYAR0zKn_5n",
      "metadata": {
        "id": "JmYAR0zKn_5n"
      },
      "outputs": [],
      "source": [
        "import scipy.stats\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "mlp = MLPClassifier(early_stopping=True)\n",
        "randomCV = RandomizedSearchCV(mlp,parameter_space)\n",
        "search = randomCV.fit(X_train, Y_train)\n",
        "search.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "911d0a39",
      "metadata": {
        "id": "911d0a39"
      },
      "source": [
        "#### Try the different algorithms and compare the results with MLP classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3727222f",
      "metadata": {
        "id": "3727222f"
      },
      "outputs": [],
      "source": [
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae52e208",
      "metadata": {
        "id": "ae52e208"
      },
      "outputs": [],
      "source": [
        "!pip install  xgboost\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5eb43876",
      "metadata": {
        "id": "5eb43876"
      },
      "outputs": [],
      "source": [
        "# Decision Tree\n",
        "dt_model_team = tree.DecisionTreeClassifier(random_state=42)\n",
        "dt_model_team = dt_model_team.fit(X_train, Y_train)\n",
        "dt_model_team.score(X_test, Y_test), dt_model_team.score(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "034293e7",
      "metadata": {
        "id": "034293e7"
      },
      "outputs": [],
      "source": [
        "# Random Forest\n",
        "rf_model_team = RandomForestClassifier(max_depth=10, n_estimators=250,criterion='entropy',random_state=42)\n",
        "rf_model_team.fit(X_train, Y_train)\n",
        "rf_model_team.score(X_test, Y_test), rf_model_team.score(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "433a7879",
      "metadata": {
        "id": "433a7879"
      },
      "outputs": [],
      "source": [
        "#Linear SVC\n",
        "Lsvm = LinearSVC(random_state=0, tol=1e-5)\n",
        "Lsvm.fit(X_train, Y_train)\n",
        "Lsvm.score(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2ca6b82",
      "metadata": {
        "id": "f2ca6b82"
      },
      "outputs": [],
      "source": [
        "svm_clf = SVC(kernel=\"rbf\",C=1.0)\n",
        "svm_clf.fit(X_train, Y_train)\n",
        "svm_clf.score(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08b0c234",
      "metadata": {
        "id": "08b0c234"
      },
      "outputs": [],
      "source": [
        "xgb = XGBClassifier()\n",
        "xgb.fit(X_train, Y_train)\n",
        "xgb.score(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af9cd34e",
      "metadata": {
        "id": "af9cd34e"
      },
      "source": [
        "### Implement simple Neural Networks using keras\n",
        "\n",
        "* Define the keras model and initialize the layers\n",
        "  - Ensure the input layer has the right number of input features. This can be specified when creating the first layer with the input_dim argument.\n",
        "* Compile the model\n",
        "  - Specify the loss function (to evaluate a set of weights), the optimizer (is used to search through different weights for the network) and any optional metrics to collect and report during training.\n",
        "* Fit and Evaluate the model\n",
        "  - Fit the data by specifying epochs and evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcf8d025",
      "metadata": {
        "id": "fcf8d025"
      },
      "outputs": [],
      "source": [
        "print(tf.__version__) # 1.12.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ecbe0db",
      "metadata": {
        "id": "1ecbe0db"
      },
      "outputs": [],
      "source": [
        "# Step 1 - Build the architecture\n",
        "# Model a simple 3-layer neural network\n",
        "nn_model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[2700]),\n",
        "    keras.layers.Dense(1350, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(675, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(43, activation=tf.nn.softmax)\n",
        "])\n",
        "nn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53e1db62",
      "metadata": {
        "id": "53e1db62"
      },
      "outputs": [],
      "source": [
        "np.array(X_train).shape, Y_train.shape, len(set(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4c7bc66",
      "metadata": {
        "id": "d4c7bc66"
      },
      "outputs": [],
      "source": [
        "# Step 2 - Compile the model\n",
        "nn_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27400de2",
      "metadata": {
        "id": "27400de2"
      },
      "outputs": [],
      "source": [
        "nn_model.fit(X_train, Y_train, epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee941659",
      "metadata": {
        "id": "ee941659"
      },
      "outputs": [],
      "source": [
        "nn_model.evaluate(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cSUDO2lLmQJO",
      "metadata": {
        "id": "cSUDO2lLmQJO"
      },
      "source": [
        "#### Try the same parameters used for MLP Classifier and build the keras model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_BUQ57D9jXQh",
      "metadata": {
        "id": "_BUQ57D9jXQh"
      },
      "outputs": [],
      "source": [
        "nn_model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[2700]),\n",
        "    keras.layers.Dense(450, activation=tf.nn.tanh),\n",
        "    keras.layers.Dense(225, activation=tf.nn.tanh),\n",
        "    keras.layers.Dense(100, activation=tf.nn.tanh),\n",
        "    keras.layers.Dense(50, activation=tf.nn.softmax)\n",
        "])\n",
        "nn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "nn_model.fit(X_train, Y_train, epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DuODt8Xzl0Vg",
      "metadata": {
        "id": "DuODt8Xzl0Vg"
      },
      "outputs": [],
      "source": [
        "nn_model.evaluate(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IAHzeVx_tImO",
      "metadata": {
        "id": "IAHzeVx_tImO"
      },
      "source": [
        "#### Experiment using Dropout, Regularization and Batch Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "U1jmTcxftqpq",
      "metadata": {
        "id": "U1jmTcxftqpq"
      },
      "outputs": [],
      "source": [
        "# With Regularization and DropOut and BatchNormalization\n",
        "nn_model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[2700]),\n",
        "    keras.layers.Dense(1350, activation=tf.nn.relu,kernel_regularizer=keras.regularizers.l2(0.01)),\n",
        "    keras.layers.Dense(675, activation=tf.nn.relu),\n",
        "    Dropout(rate=0.1),\n",
        "    BatchNormalization(),\n",
        "    keras.layers.Dense(43, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "nn_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "nn_model.fit(X_train, Y_train, epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "F0Qesi0dt0Gu",
      "metadata": {
        "id": "F0Qesi0dt0Gu"
      },
      "outputs": [],
      "source": [
        "nn_model.evaluate(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MhWaGRRfs7tv",
      "metadata": {
        "id": "MhWaGRRfs7tv"
      },
      "source": [
        "### Report Analysis\n",
        "\n",
        "* According to the confusion matrix, for which sign were the maximum misclassifications observed? Comment on the misclassification, owing to similar appearing traffic signs, if any.\n",
        "* Comment on the performance of the MLP Classifier\n",
        "* Discuss the optimal number of layers, activation functions, optimizers etc. that yielded the best accuracy\n",
        "* Report on training time vs convergence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CjZOi2tsKuMn",
      "metadata": {
        "id": "CjZOi2tsKuMn"
      },
      "outputs": [],
      "source": [
        "predict_test = nn_model.predict(X_test)\n",
        "predict_test = np.argmax(predict_test,axis=1)\n",
        "predict_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OImi9JCWLXRm",
      "metadata": {
        "id": "OImi9JCWLXRm"
      },
      "outputs": [],
      "source": [
        "metrics.confusion_matrix(Y_test, predict_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FyGQBXTOLhzF",
      "metadata": {
        "id": "FyGQBXTOLhzF"
      },
      "outputs": [],
      "source": [
        "print(metrics.classification_report(Y_test, predict_test))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
